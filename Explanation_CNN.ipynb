{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Explanation-of-a-CNN-Model\" data-toc-modified-id=\"Explanation-of-a-CNN-Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Explanation of a CNN Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Layers-of-a-CNN\" data-toc-modified-id=\"Layers-of-a-CNN-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Layers of a CNN</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#The-Activation-Function\" data-toc-modified-id=\"The-Activation-Function-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>The Activation Function</a></span></li><li><span><a href=\"#The-Pooling-Layer\" data-toc-modified-id=\"The-Pooling-Layer-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>The Pooling Layer</a></span></li><li><span><a href=\"#The-DropOut-Layer\" data-toc-modified-id=\"The-DropOut-Layer-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>The DropOut Layer</a></span></li><li><span><a href=\"#The-Flattened-layer-leading-to-the-Fully-Connected-Dense-layers\" data-toc-modified-id=\"The-Flattened-layer-leading-to-the-Fully-Connected-Dense-layers-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>The Flattened layer leading to the Fully Connected Dense layers</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of a CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Image classification is the task of taking an input image and outputting a class (a cat, dog, etc) or a probability of classes that best describes the image. When a computer sees an image, it sees an array of pixel values.If an image is 32x33, it will see an array of 32x32x3 (the 3 stands for the RGB layers). Each of these array values has a number between 0 and 255 which describes the pixel intensity at that point.  The idea is that you give the computer this array of numbers and it will output numbers that describe the probability of the image being a certain class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a illustrative graphic that shows what is happening at each layer of the convoluted neural network. This graphic is an image (the input) being passed through the model, and a filter (Conv2D) passing through the image and taking the dot product of the pixel values and applying Relu (Rectified Linear Unit) to get a number between 0 and infinity. The pooling layer (MaxPooling2D) takes the maximum values from the convolution layer and reduces the dimensions of the image (and also helps speed up processing time). The flattened layer (Flatten()) takes the image pixels in the previous layer and flattens it out (32 x 32 x 2000 = 1280). The Dropout layer randomly ignores certain neurons and helps prevent overfitting. The densely connected layer (Dense) is connected to every node in the previous layer and applies ReLu to its output values. Finally, the output layer (also Dense) applies the softmax activation function to show probabilities for all 46 characters, and all of the probabilities will add up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/cnn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers of a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1st layer is the Convolutional layer. The input to this convolutional layer is the 32x32x3 pixel values. A filter of a certain dimension, say 5x5 is applied to the to the top left of the convulutional layer. This filter is also an array of numbers called weights.  As the filter slides, or convolves, around the input image, it is multiplying the values in the filter with the original pixel values of the image (aka computing element wise multiplications). These multiplications are all summed up to give us a single number. This number is just representative of when the filter is at the top left of the image. We repeat this process for every location on the input volume. (Next step would be moving the filter to the right by 1 unit, then right again by 1, and so on). Every unique location on the input volume produces a number. After sliding the filter over all the locations, you will find out that what youâ€™re left with is a 28 x 28 x 1 array of numbers, which we call an activation map or feature map. We do this for many more filter layers. and get many more arrays. These filters in the 1st few layers of the model detect low level features such as edges and curves.\n",
    "The output of the 1st layer becomes the input for the 2nd layer. So each layer of the input is basically describing the locations in the original image for where certain low level features appear. Now when you apply a set of filters on top of that (pass it through the 2nd conv layer), the output will be activated that represent higher level features. Types of these features could be semicircles (combination of a curve and straight edge) or squares (combination of several straight edges). As you go through the network and go through more conv layers, you get activation maps that represent more and more complex features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 main parameters that we can control in a CNN model. The filter size, the stride and the padding. As you can see in the figure a stride of 1 will reduce a 7x7 input into a 5x5 output volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stride1](./images/stride1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stide of 2 will reduce it to a 3x3 output volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stride1](./images/stride2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also applying ReLU (Rectified Linear Unit) activation function to get a number between 0 and infinity. After each Convolutional layer, it is convention to apply a non linear layer immediately afterwards. The purpose of this layer is to introduce non linearity to a system that basically has just been computing linear operations during the conv. layers (just element wise summations and multiplications). In the past non-linear functions like Tanh and sigmoid were used, bur researches found that the ReLU layers work better because the network is able to train a lot faster without making a significant difference to the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pooling Layer basically takes a filter and a stride of the same length. It then applies it to the input volume and outputs the maximum number in every sub region that the filter convolves around. This reduces the dimensions of the image and helps speed up processing times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DropOut Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dropout layer is a Regularization method to prevent overfitting. During training, some number of layer outputs are randomly ignored or 'dropped out'. This has the effect of making the layer look like and be treated like a layer with a different number of nodes and connectivity to the prior layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Flattened layer leading to the Fully Connected Dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can detect these high level features, we can attach a fully connected layer to the end of the network. This layer basically takes an input volume (whatever the output is of the conv or ReLU or pool layer preceding it) and outputs an N dimensional vector where N is the number of classes that the program has to choose from. Each number in this N dimensional vector represents the probability of a certain class.Basically, a Fully Connected layer looks at what high level features most strongly correlate to a particular class and has particular weights so that when you compute the products between the weights and the previous layer, you get the correct probabilities for the different classes.It applies the SoftMax activation function to show probabilities for all the classes and these probabilities add up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "224.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
